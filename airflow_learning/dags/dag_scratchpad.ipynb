{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a7a1ff0-a5d2-40b8-8d7e-d9c0630706d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime(2025, 12, 16, 3, 24, 0, tzinfo=Timezone('UTC'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# really importans stuff: this gets us time at utc 15 minutes ago\n",
    "import pendulum\n",
    "pendulum.now().set(second=0, microsecond=0).in_timezone(\"UTC\").subtract(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af78852e-6cda-4720-ae0a-d1252451d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tickers\n",
    "tickers = get_tickers()\n",
    "latest_bars = get_latest_bars(tickers, headers_alpaca)\n",
    "type(latest_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f23b228-e46a-4c19-943b-b896a2d875b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-16 04:10:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# no taskflow\n",
    "import pendulum\n",
    "import tasks_alpaca\n",
    "\n",
    "from airflow.providers.standard.operators.python import PythonOperator\n",
    "from airflow.sdk import DAG\n",
    "from minio import Minio\n",
    "from pathlib import Path\n",
    "\n",
    "# minio conn\n",
    "login_minio, password_minio = tasks_alpaca.get_minio_credentials()\n",
    "host = \"localhost\"\n",
    "client = Minio(\n",
    "    endpoint=f\"{host}:9000\",\n",
    "    access_key=login_minio,\n",
    "    secret_key=password_minio,\n",
    "    secure=False\n",
    "    )\n",
    "\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"get_latest_bars\",\n",
    "    catchup=False,\n",
    "    tags=\"stonks\",\n",
    "    start_date=pendulum.now().set(second=0, microsecond=0).in_timezone(\"UTC\").subtract(minutes=15),\n",
    "    schedule=pendulum.duration(minutes=1)\n",
    ") as dag:\n",
    "    \n",
    "    tickers = PythonOperator(\n",
    "        task_id=\"get_ticker_list\",\n",
    "        python_callable=tasks_alpaca.get_tickers,\n",
    "        op_kwargs={\"path_to_json\": Path().cwd() / \"data\" / \"tickers.json\"},\n",
    "        dag=dag)\n",
    "    bars = PythonOperator(\n",
    "        task_id=\"get_latest_bars\",\n",
    "        python_callable=tasks_alpaca.get_latest_bars,\n",
    "        op_kwargs={\"tickers_to_search\": tickers},\n",
    "        dag=dag)\n",
    "    save_data = PythonOperator(\n",
    "        task_id=\"save_data_to_bronze_bucket\",\n",
    "        python_callable=tasks_alpaca.upload_to_bucket,\n",
    "        op_kwargs={\n",
    "            \"source_file\":bars,\n",
    "            \"bucket_name\":\"learning.bronze\",\n",
    "            \"client\": client,\n",
    "            \"destination_file\":dag.start_date\n",
    "        })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc8034b3-44e2-42c6-955e-e02a11fc2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime taskflow\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pendulum \n",
    "import requests\n",
    "\n",
    "from airflow.sdk import dag, task\n",
    "from dotenv import load_dotenv\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from pathlib import Path\n",
    "from tasks_alpaca import get_minio_credentials, create_bucket\n",
    "from typing import Union, Tuple, Optional\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "credentials = {\n",
    "        \"key\": \"PKCTYL4MO5SA2QEIZL2TDEJRTA\",\n",
    "        \"secret_key\": \"DKL2eLVYFcxKzMJtDYbuG3zppWjpwHzsTS1DtHVwc9Cz\"\n",
    "    }\n",
    "headers_alpaca = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"APCA-API-KEY-ID\": credentials[\"key\"],\n",
    "    \"APCA-API-SECRET-KEY\": credentials[\"secret_key\"]\n",
    "}\n",
    "\n",
    "# minio conn\n",
    "login_minio, password_minio = get_minio_credentials()\n",
    "host = \"localhost\"\n",
    "client = Minio(\n",
    "    endpoint=f\"{host}:9001\",\n",
    "    access_key=login_minio,\n",
    "    secret_key=password_minio,\n",
    "    secure=False\n",
    "    )\n",
    "\n",
    "def get_realtime_tickers():\n",
    "    @task\n",
    "    def get_tickers(path_to_json: Optional[Path] = None) -> list:\n",
    "        if path_to_json is None:\n",
    "            return ['aapl', 'nvda']\n",
    "        with open(path_to_json, \"r\") as tickers_file:\n",
    "            tickers = json.load(tickers_file)\n",
    "        return tickers\n",
    "    @task\n",
    "    def get_latest_bars(tickers_to_search):\n",
    "        print(tickers_to_search)\n",
    "        params = {\n",
    "            'symbols': \",\".join(tickers_to_search),\n",
    "            }\n",
    "        url = f\"https://data.alpaca.markets/v2/stocks/bars/latest?{urlencode(params)}\"\n",
    "        response = requests.get(url, headers=headers_alpaca)\n",
    "        return response.text\n",
    "    @task    \n",
    "    def upload_to_bucket(source_file: Union[str, Path, bytes], bucket_name: str, client: Minio, destination_file: str=None) -> None:\n",
    "        # Make the bucket if it doesn't exist.\n",
    "        create_bucket(bucket_name, client)\n",
    "        # Encode str to bytes\n",
    "        file_encoded = source_file.encode(\"utf-8\")\n",
    "        file_to_upload = io.BytesIO(file_encoded)\n",
    "        # Upload file\n",
    "        client.put_object(\n",
    "            data=file_to_upload,\n",
    "            bucket_name=bucket_name,\n",
    "            object_name=destination_file,\n",
    "            length=len(file_encoded)\n",
    "        )\n",
    "        print(\"Successfully uploaded object\", destination_file, \"to bucket\", bucket_name)\n",
    "\n",
    "    tickers = get_tickers()\n",
    "    bars = get_latest_bars(tickers)\n",
    "    upload_to_bucket(source_file=bars, bucket_name=\"airflow.learn\", client=client, destination_file=\"{{dag_run.start_date}}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bd47075-1ddc-4dee-b749-5e3bad197eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aapl', 'nvda']\n",
      "Bucket airflow.learn already exists\n",
      "Successfully uploaded object test_upload.txt to bucket airflow.learn\n"
     ]
    }
   ],
   "source": [
    "get_realtime_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bb50739-e612-40db-b3b6-24ea2aa2d8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('airflow_learning/data/tickers.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"airflow_learning/data/tickers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a186927a-f423-4871-9c72-cafc78dfb18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/heinz/python-workspace/stonks/airflow_learning/dags'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3dcc5a79-4934-4ebe-b08e-70d9ab3f6ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asss'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (Path(\"/home/heinz/python-workspace/stonks/data/latest\"), \"rb\") as file:\n",
    "    bars = file.read().decode()\n",
    "bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ecf20-dd93-40ed-9fc3-6227bc335b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft 15:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50315f-36f1-42a6-a10c-91b2bd28ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime taskflow\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pendulum \n",
    "import requests\n",
    "\n",
    "from airflow.sdk import dag, task\n",
    "from dotenv import load_dotenv\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from pathlib import Path\n",
    "from tasks_alpaca import get_minio_credentials, create_bucket\n",
    "from typing import Union, Tuple, Optional\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "\n",
    "credentials = {\n",
    "        \"key\": \"PKCTYL4MO5SA2QEIZL2TDEJRTA\",\n",
    "        \"secret_key\": \"DKL2eLVYFcxKzMJtDYbuG3zppWjpwHzsTS1DtHVwc9Cz\"\n",
    "    }\n",
    "headers_alpaca = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"APCA-API-KEY-ID\": credentials[\"key\"],\n",
    "    \"APCA-API-SECRET-KEY\": credentials[\"secret_key\"]\n",
    "}\n",
    "\n",
    "# minio conn\n",
    "login_minio, password_minio = get_minio_credentials()\n",
    "host = \"localhost\"\n",
    "client = Minio(\n",
    "    endpoint=f\"{host}:9001\",\n",
    "    access_key=login_minio,\n",
    "    secret_key=password_minio,\n",
    "    secure=False\n",
    "    )\n",
    "\n",
    "def get_latest_bars(tickers_to_search):\n",
    "    print(tickers_to_search)\n",
    "    params = {\n",
    "        'symbols': \",\".join(tickers_to_search),\n",
    "        }\n",
    "    url = f\"https://data.alpaca.markets/v2/stocks/bars/latest?{urlencode(params)}\"\n",
    "    response = requests.get(url, headers=headers_alpaca)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa3b16-510b-4dec-bd3b-254875ef97a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "первый запуск: \n",
    "1) собираем историю за сегодня и берем последний тик\n",
    "2) собираем историю за последние 80 дней с группировкой по 3 часа\n",
    "3) повторяем 2 на нужном периоде:\n",
    "    - смотрим самую раннюю дату на файлах и берем её как энд_дэйт, от нее последние 80 дней собираем\n",
    "4) когда собрали за нужный период, увеличиваем зернистость: по 1 часу, после - по минуте\n",
    "5) Чтобы не искать каждый раз раннюю дату, можно сделать какой-нибудь флаг, который показывает, где даг остановился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eeb613-38ab-4c1b-acc9-af9b4ade51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_earliest_bars(path_to_bars: Union[str, Path]) -> pendulum.Date:\n",
    "    end_date = pendulum.today().date()\n",
    "    bars_items = list(Path(path_to_bars).iterdir())\n",
    "    if len(bars_items) > 0:\n",
    "        #find earliest date\n",
    "        for item in bars_items:\n",
    "            date_str = item.name.split(\"-\")[0].split(\"_\")[1]\n",
    "            date_parsed = pendulum.parse(date_str, tz=\"UTC\").date()\n",
    "            if date_parsed < end_date:\n",
    "                end_date = date_parsed\n",
    "    return end_date\n",
    "    \n",
    "def get_historical_bars(\n",
    "    tickers_to_search: list[str],\n",
    "    time_frame: str = \"3H\",\n",
    "    date_start: str = None,\n",
    "    date_end: str = None,\n",
    "    limit: int = 10000,\n",
    "    page_token: str = \"\") -> Tuple[str, bool]:\n",
    "    \"\"\" \n",
    "        Saves json in file or prints errors made in arguments.\n",
    "        Args:\n",
    "            tickers_to_search:\n",
    "                non-empty list of stock tickers.\n",
    "            time_frame:\n",
    "                [1-59]Min or [1-59]T, e.g. 5Min or 5T creates 5-minute aggregations.\n",
    "                [1-23]Hour or [1-23]H, e.g. 12Hour or 12H creates 12-hour aggregations.\n",
    "                1Day or 1D creates 1-day aggregations.\n",
    "                1Week or 1W creates 1-week aggregations.\n",
    "                [1,2,3,4,6,12]Month or [1,2,3,4,6,12]M, e.g. 3Month or 3M creates 3-month aggregations.\n",
    "            date_start and date-end:\n",
    "                string in YYYY-MM-DD or rfc-3339 format. date_start should be an earlier date than date_end.\n",
    "            limit: \n",
    "                number between 1 and 10000.\n",
    "            page_token:\n",
    "                a string you get from 'next_page_token' field of response.\n",
    "                If this is the first page of your call, then leave it as empty string.\n",
    "                If there is no next page for your call, 'next_page_token' field will return None value. This behavior is expected.\n",
    "        Returns:\n",
    "            Tuple(bars, is_there_next_page) \n",
    "                \"\"\"\n",
    "        \n",
    "    # # Validate arguments\n",
    "    # is_valid, error_messages = validate_arguments(tickers_to_search, date_start, date_end, time_frame, limit)\n",
    "    # if not is_valid:\n",
    "    #     for error in error_messages:\n",
    "    #         print(error)\n",
    "    #     return False\n",
    "    \n",
    "    params = {\n",
    "    'symbols': \",\".join(tickers_to_search),\n",
    "    'timeframe': time_frame, \n",
    "    'start': date_start,\n",
    "    'end': date_end,\n",
    "    'limit': limit,\n",
    "    'adjustment': 'raw',\n",
    "    'feed': 'sip', \n",
    "    'page_token': \"\",\n",
    "    'sort': \"asc\"\n",
    "    }\n",
    "    while params['page_token'] is not None: # while there is next page\n",
    "        url = f\"https://data.alpaca.markets/v2/stocks/bars?{urlencode(params)}\"\n",
    "        response = requests.get(url, headers=headers_alpaca)\n",
    "        parsed = json.loads(response.text)\n",
    "        params['page_token'] = parsed['next_page_token']\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d37db9-bf89-4dd8-b41f-afddf447fadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_test_dag.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "items = list(Path().cwd().iterdir())\n",
    "items[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b512c2f-41cc-4ce5-9f48-043f43aeccb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "len(Path().cwd().iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6773beef-85c8-44f8-ab4b-05f7f3616786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime(2025, 12, 10, 10, 14, 0, tzinfo=Timezone('UTC'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pendulum\n",
    "date=\"2025-12-10T10:14:00Z\"\n",
    "pendulum.parse(date,tz=\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd972546-b9a0-45ba-8db2-c3854c27fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    tickers_to_search: list[str],\n",
    "    time_frame: str = \"3H\",\n",
    "    date_start: str = None,\n",
    "    date_end: str = None,\n",
    "    limit: int = 10000,\n",
    "    page_token: str = \"\") -> Tuple[str, bool]:\n",
    "date_end = find_earliest_bars(#path)\n",
    "get_historical_bars(tickers, time_frame=\"3H\", date_start=date_end.subtract(days=80), date_end=date_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
