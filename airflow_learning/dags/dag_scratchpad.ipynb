{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a7a1ff0-a5d2-40b8-8d7e-d9c0630706d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime(2025, 12, 16, 3, 24, 0, tzinfo=Timezone('UTC'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# really importans stuff: this gets us time at utc 15 minutes ago\n",
    "import pendulum\n",
    "pendulum.now().set(second=0, microsecond=0).in_timezone(\"UTC\").subtract(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d47b01-cd3f-4b8e-adb5-08b1a9d917da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "credentials = {\n",
    "        \"key\": \"PKCTYL4MO5SA2QEIZL2TDEJRTA\",\n",
    "        \"secret_key\": \"DKL2eLVYFcxKzMJtDYbuG3zppWjpwHzsTS1DtHVwc9Cz\",\n",
    "        \"finnhub\": \"d4ofku9r01quuso9dtkgd4ofku9r01quuso9dtl0\"\n",
    "    }\n",
    "headers_alpaca = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"APCA-API-KEY-ID\": credentials[\"key\"],\n",
    "    \"APCA-API-SECRET-KEY\": credentials[\"secret_key\"]\n",
    "}\n",
    "\n",
    "\n",
    "def get_tickers(path_to_json: Optional[Path] = None) -> list:\n",
    "    if path_to_json is None:\n",
    "        return ['aapl', 'nvda']\n",
    "    with open(path_to_json, \"r\") as tickers_file:\n",
    "        tickers = json.load(tickers_file)\n",
    "    return tickers\n",
    "\n",
    "    \n",
    "def get_latest_bars(tickers_to_search, headers):\n",
    "    \n",
    "    params = {\n",
    "        'symbols': \",\".join(tickers_to_search),\n",
    "        }\n",
    "    url = f\"https://data.alpaca.markets/v2/stocks/bars/latest?{urlencode(params)}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af78852e-6cda-4720-ae0a-d1252451d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = get_tickers()\n",
    "latest_bars = get_latest_bars(tickers, headers_alpaca)\n",
    "type(latest_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f23b228-e46a-4c19-943b-b896a2d875b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-16 04:10:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# no taskflow\n",
    "import pendulum\n",
    "import tasks_alpaca\n",
    "\n",
    "from airflow.providers.standard.operators.python import PythonOperator\n",
    "from airflow.sdk import DAG\n",
    "from minio import Minio\n",
    "from pathlib import Path\n",
    "\n",
    "# minio conn\n",
    "login_minio, password_minio = tasks_alpaca.get_minio_credentials()\n",
    "host = \"localhost\"\n",
    "client = Minio(\n",
    "    endpoint=f\"{host}:9000\",\n",
    "    access_key=login_minio,\n",
    "    secret_key=password_minio,\n",
    "    secure=False\n",
    "    )\n",
    "\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"get_latest_bars\",\n",
    "    catchup=False,\n",
    "    tags=\"stonks\",\n",
    "    start_date=pendulum.now().set(second=0, microsecond=0).in_timezone(\"UTC\").subtract(minutes=15),\n",
    "    schedule=pendulum.duration(minutes=1)\n",
    ") as dag:\n",
    "    \n",
    "    tickers = PythonOperator(\n",
    "        task_id=\"get_ticker_list\",\n",
    "        python_callable=tasks_alpaca.get_tickers,\n",
    "        op_kwargs={\"path_to_json\": Path().cwd() / \"data\" / \"tickers.json\"},\n",
    "        dag=dag)\n",
    "    bars = PythonOperator(\n",
    "        task_id=\"get_latest_bars\",\n",
    "        python_callable=tasks_alpaca.get_latest_bars,\n",
    "        op_kwargs={\"tickers_to_search\": tickers},\n",
    "        dag=dag)\n",
    "    save_data = PythonOperator(\n",
    "        task_id=\"save_data_to_bronze_bucket\",\n",
    "        python_callable=tasks_alpaca.upload_to_bucket,\n",
    "        op_kwargs={\n",
    "            \"source_file\":bars,\n",
    "            \"bucket_name\":\"learning.bronze\",\n",
    "            \"client\": client,\n",
    "            \"destination_file\":dag.start_date\n",
    "        })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8cdff8b-151e-490c-9785-4828f60b1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime taskflow\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pendulum \n",
    "import requests\n",
    "\n",
    "from airflow.sdk import dag, task\n",
    "from dotenv import load_dotenv\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from pathlib import Path\n",
    "from tasks_alpaca import get_minio_credentials, upload_to_bucket\n",
    "from typing import Union, Tuple, Optional\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "credentials = {\n",
    "        \"key\": \"PKCTYL4MO5SA2QEIZL2TDEJRTA\",\n",
    "        \"secret_key\": \"DKL2eLVYFcxKzMJtDYbuG3zppWjpwHzsTS1DtHVwc9Cz\"\n",
    "    }\n",
    "headers_alpaca = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"APCA-API-KEY-ID\": credentials[\"key\"],\n",
    "    \"APCA-API-SECRET-KEY\": credentials[\"secret_key\"]\n",
    "}\n",
    "\n",
    "# minio conn\n",
    "login_minio, password_minio = get_minio_credentials()\n",
    "host = \"localhost\"\n",
    "client = Minio(\n",
    "    endpoint=f\"{host}:9000\",\n",
    "    access_key=login_minio,\n",
    "    secret_key=password_minio,\n",
    "    secure=False\n",
    "    )\n",
    "\n",
    "\n",
    "@dag(\n",
    "    dag_id=\"get_latest_bars\",\n",
    "    catchup=False,\n",
    "    tags=\"stonks\",\n",
    "    start_date=pendulum.now().set(second=0, microsecond=0).in_timezone(\"UTC\").subtract(minutes=15),\n",
    "    schedule=pendulum.duration(minutes=1))\n",
    "def get_realtime_tickers():\n",
    "    \n",
    "    @task\n",
    "    def get_tickers(path_to_json: Optional[Path] = None) -> list:\n",
    "        if path_to_json is None:\n",
    "            return {\"tickers_to_search\": ['aapl', 'nvda']}\n",
    "        with open(path_to_json, \"r\") as tickers_file:\n",
    "            tickers = json.load(tickers_file)\n",
    "        return {\"tickers_to_search\": tickers}\n",
    "        \n",
    "    @task\n",
    "    def get_latest_bars(tickers_to_search):\n",
    "        print(tickers_to_search)\n",
    "        params = {\n",
    "            'symbols': \",\".join(tickers_to_search),\n",
    "            }\n",
    "        url = f\"https://data.alpaca.markets/v2/stocks/bars/latest?{urlencode(params)}\"\n",
    "        response = requests.get(url, headers=headers_alpaca)\n",
    "        return response.text\n",
    "        \n",
    "    @task\n",
    "    upload_to_bucket()\n",
    "\n",
    "    tickers = get_tickers()\n",
    "    bars = get_latest_bars(tickers)\n",
    "    upload_to_bucket(source_file=bars, bucket_name=\"airflow.learn\", client=client, destination_file=\"{{dag_run.start_date}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de4bf895-8a65-4422-ad15-cde9df141f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DAG: get_latest_bars>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_realtime_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc8034b3-44e2-42c6-955e-e02a11fc2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime taskflow\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pendulum \n",
    "import requests\n",
    "\n",
    "from airflow.sdk import dag, task\n",
    "from dotenv import load_dotenv\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from pathlib import Path\n",
    "from tasks_alpaca import get_minio_credentials, create_bucket\n",
    "from typing import Union, Tuple, Optional\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "credentials = {\n",
    "        \"key\": \"PKCTYL4MO5SA2QEIZL2TDEJRTA\",\n",
    "        \"secret_key\": \"DKL2eLVYFcxKzMJtDYbuG3zppWjpwHzsTS1DtHVwc9Cz\"\n",
    "    }\n",
    "headers_alpaca = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"APCA-API-KEY-ID\": credentials[\"key\"],\n",
    "    \"APCA-API-SECRET-KEY\": credentials[\"secret_key\"]\n",
    "}\n",
    "\n",
    "# minio conn\n",
    "login_minio, password_minio = get_minio_credentials()\n",
    "host = \"localhost\"\n",
    "client = Minio(\n",
    "    endpoint=f\"{host}:9001\",\n",
    "    access_key=login_minio,\n",
    "    secret_key=password_minio,\n",
    "    secure=False\n",
    "    )\n",
    "\n",
    "def get_realtime_tickers():\n",
    "    @task\n",
    "    def get_tickers(path_to_json: Optional[Path] = None) -> list:\n",
    "        if path_to_json is None:\n",
    "            return ['aapl', 'nvda']\n",
    "        with open(path_to_json, \"r\") as tickers_file:\n",
    "            tickers = json.load(tickers_file)\n",
    "        return tickers\n",
    "    @task\n",
    "    def get_latest_bars(tickers_to_search):\n",
    "        print(tickers_to_search)\n",
    "        params = {\n",
    "            'symbols': \",\".join(tickers_to_search),\n",
    "            }\n",
    "        url = f\"https://data.alpaca.markets/v2/stocks/bars/latest?{urlencode(params)}\"\n",
    "        response = requests.get(url, headers=headers_alpaca)\n",
    "        return response.text\n",
    "    @task    \n",
    "    def upload_to_bucket(source_file: Union[str, Path, bytes], bucket_name: str, client: Minio, destination_file: str=None) -> None:\n",
    "        # Make the bucket if it doesn't exist.\n",
    "        create_bucket(bucket_name, client)\n",
    "        # Encode str to bytes\n",
    "        file_encoded = source_file.encode(\"utf-8\")\n",
    "        file_to_upload = io.BytesIO(file_encoded)\n",
    "        # Upload file\n",
    "        client.put_object(\n",
    "            data=file_to_upload,\n",
    "            bucket_name=bucket_name,\n",
    "            object_name=destination_file,\n",
    "            length=len(file_encoded)\n",
    "        )\n",
    "        print(\"Successfully uploaded object\", destination_file, \"to bucket\", bucket_name)\n",
    "\n",
    "    tickers = get_tickers()\n",
    "    bars = get_latest_bars(tickers)\n",
    "    upload_to_bucket(source_file=bars, bucket_name=\"airflow.learn\", client=client, destination_file=\"{{dag_run.start_date}}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bd47075-1ddc-4dee-b749-5e3bad197eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aapl', 'nvda']\n",
      "Bucket airflow.learn already exists\n",
      "Successfully uploaded object test_upload.txt to bucket airflow.learn\n"
     ]
    }
   ],
   "source": [
    "get_realtime_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bb50739-e612-40db-b3b6-24ea2aa2d8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('airflow_learning/data/tickers.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"airflow_learning/data/tickers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a186927a-f423-4871-9c72-cafc78dfb18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/heinz/python-workspace/stonks/airflow_learning/dags'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3dcc5a79-4934-4ebe-b08e-70d9ab3f6ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asss'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (Path(\"/home/heinz/python-workspace/stonks/data/latest\"), \"rb\") as file:\n",
    "    bars = file.read().decode()\n",
    "bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ecf20-dd93-40ed-9fc3-6227bc335b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
